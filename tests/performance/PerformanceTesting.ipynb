{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: aiohttp in /Users/carlos/anaconda3/lib/python3.7/site-packages (3.6.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/carlos/anaconda3/lib/python3.7/site-packages (from aiohttp) (19.3.0)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in /Users/carlos/anaconda3/lib/python3.7/site-packages (from aiohttp) (4.7.6)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/carlos/anaconda3/lib/python3.7/site-packages (from aiohttp) (1.5.1)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /Users/carlos/anaconda3/lib/python3.7/site-packages (from aiohttp) (3.0.4)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /Users/carlos/anaconda3/lib/python3.7/site-packages (from aiohttp) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /Users/carlos/anaconda3/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp) (3.7.4.1)\n",
      "Requirement already satisfied: idna>=2.0 in /Users/carlos/anaconda3/lib/python3.7/site-packages (from yarl<2.0,>=1.0->aiohttp) (2.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install aiohttp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import json\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String\n",
    "import urllib\n",
    "from pandas.io import sql\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import requests\n",
    "from time import perf_counter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigReader:\n",
    "    def get_value(self, key):\n",
    "        with open('config.json') as json_data_file:\n",
    "            data = json.load(json_data_file)\n",
    "        return data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DbManager:\n",
    "    def __init__(self):\n",
    "        reader = ConfigReader()\n",
    "        db_connection = reader.get_value(\"db_connection\")        \n",
    "        self.conn_string = '{db_engine}{connector}://{user}:{password}@{server}/{database}'.format(\n",
    "            db_engine=db_connection['db_engine'],\n",
    "            connector=db_connection['connector'],\n",
    "            user=db_connection['user'],\n",
    "            password=db_connection['password'],\n",
    "            server=db_connection['server'],\n",
    "            database=db_connection['database'])\n",
    "\n",
    "    def get_users(self):\n",
    "        return sql.read_sql(\"SELECT distinct userId FROM ratings;\", create_engine(self.conn_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get random users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rand_users = 100\n",
    "dbManager = DbManager()\n",
    "db_users = dbManager.get_users()\n",
    "n_rand_users = db_users.sample(n=n_rand_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test recommendation endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://127.0.0.1:8000'\n",
    "algo_rec = 'popular'\n",
    "algo_pred = 'biasedmf'\n",
    "n_recs = 5\n",
    "items = \"10,20,30,40,50\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(times, time_taken_all, num_requests):\n",
    "    print(f'Total response time: {time_taken_all}')\n",
    "#   print(f'Average load time: {time_taken_all / num_requests}')\n",
    "    print(f'Mean response time: {np.mean(times)}')\n",
    "    print(f'99 percentile: {np.quantile(times, 0.99)}')\n",
    "    print(f'Throughput (requests per second): {num_requests / time_taken_all}')\n",
    "    print(f'Peak response time: {max(times)}')\n",
    "    \n",
    "async def get_recs():\n",
    "    times = []\n",
    "    num_requests = len(n_rand_users)\n",
    "    print(f'Number of requests: {num_requests}')\n",
    "    start_recs = perf_counter()\n",
    "    for idx, row in n_rand_users.iterrows():\n",
    "        start = perf_counter()\n",
    "        await get_user_results(row['userId'], n_recs, algo_rec, None)\n",
    "        time_taken = perf_counter() - start\n",
    "        times.append(time_taken)\n",
    "#        print(f'Response time: {time_taken}')\n",
    "    time_taken_all = perf_counter() - start_recs\n",
    "    print_stats(times, time_taken_all, num_requests)\n",
    "\n",
    "async def get_preds():\n",
    "    times = []\n",
    "    start_preds = perf_counter()\n",
    "    num_requests = len(n_rand_users)\n",
    "    print(f'Number of requests: {num_requests}')    \n",
    "    for idx, row in n_rand_users.iterrows():\n",
    "        start = perf_counter()\n",
    "        await get_user_results(row['userId'], None, algo_pred, items)\n",
    "        time_taken = perf_counter() - start\n",
    "        times.append(time_taken)\n",
    "#        print(f'Response time: {time_taken}')\n",
    "    time_taken_all = perf_counter() - start_preds\n",
    "    print_stats(times, time_taken_all, num_requests)\n",
    "    \n",
    "async def get_user_results(userId, nr_recs, algo, items):\n",
    "    is_a_rec_request = True if algo == 'popular' or algo == 'topn' else False\n",
    "    if is_a_rec_request:\n",
    "        url = f'{base_url}/algorithms/{algo}/recommendations?user_id={userId}&num_recs={nr_recs}'\n",
    "    else:\n",
    "        url = f'{base_url}/algorithms/{algo}/predictions?user_id={userId}&items={items}'\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as resp:\n",
    "            data = await resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions results\n",
      "Number of requests: 100\n",
      "Total response time: 9.555078153000068\n",
      "Mean response time: 0.09527607532999355\n",
      "99 percentile: 0.12900826165972837\n",
      "Throughput (requests per second): 10.46563915006832\n",
      "Peak response time: 0.13945391600009316\n"
     ]
    }
   ],
   "source": [
    "print('Predictions results')\n",
    "loop = asyncio.get_event_loop()\n",
    "await loop.create_task(get_preds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendation results\n",
      "Number of requests: 100\n",
      "Total response time: 0:00:03.759398\n",
      "Mean response time: 0:00:00.037323\n",
      "99 percentile: 0:00:00.046988\n",
      "Throughput (requests per second): 26.600003511200462\n",
      "Peak response time: 0:00:00.054098\n"
     ]
    }
   ],
   "source": [
    "print('Recomendation results')\n",
    "loop = asyncio.get_event_loop()\n",
    "await loop.create_task(get_recs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single thread performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats_single_thread(times, time_taken_all, num_requests):\n",
    "    print(f'Total response time: {time_taken_all}')\n",
    "#   print(f'Average load time: {time_taken_all / num_requests}')\n",
    "    print(f'Mean response time: {np.mean(times)}')\n",
    "    print(f'99 percentile: {np.quantile(times, 0.99)}')\n",
    "    print(f'Throughput (requests per second): {num_requests / time_taken_all}')\n",
    "    print(f'Peak response time: {max(times)}')\n",
    "    \n",
    "def get_recs_single_thread():\n",
    "    times = []\n",
    "    num_requests = len(n_rand_users)\n",
    "    print(f'Number of requests: {num_requests}')\n",
    "    start_recs = perf_counter()\n",
    "    for idx, row in n_rand_users.iterrows():\n",
    "        start = perf_counter()\n",
    "        get_user_results_single_thread(row['userId'], n_recs, algo_rec, None)\n",
    "        time_taken = perf_counter() - start\n",
    "        times.append(time_taken)\n",
    "#        print(f'Response time: {time_taken}')\n",
    "    time_taken_all = perf_counter() - start_recs\n",
    "    print_stats_single_thread(times, time_taken_all, num_requests)\n",
    "\n",
    "def get_preds_single_thread():\n",
    "    times = []\n",
    "    start_preds = perf_counter()\n",
    "    num_requests = len(n_rand_users)\n",
    "    print(f'Number of requests: {num_requests}')    \n",
    "    for idx, row in n_rand_users.iterrows():\n",
    "        start = perf_counter()\n",
    "        get_user_results_single_thread(row['userId'], None, algo_pred, items)\n",
    "        time_taken = perf_counter() - start\n",
    "        times.append(time_taken)\n",
    "#        print(f'Response time: {time_taken}')\n",
    "    time_taken_all = perf_counter() - start_preds\n",
    "    print_stats_single_thread(times, time_taken_all, num_requests)\n",
    "    \n",
    "def get_user_results_single_thread(userId, nr_recs, algo, items):\n",
    "    is_a_rec_request = True if algo == 'popular' or algo == 'topn' else False\n",
    "    if is_a_rec_request:\n",
    "        url = f'{base_url}/algorithms/{algo}/recommendations?user_id={userId}&num_recs={nr_recs}'\n",
    "    else:\n",
    "        url = f'{base_url}/algorithms/{algo}/predictions?user_id={userId}&items={items}'\n",
    "\n",
    "    r = requests.get(url)\n",
    "    data = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions results in single thread\n",
      "Number of requests: 100\n",
      "Total response time: 9.780862635000176\n",
      "Mean response time: 0.09751367831001062\n",
      "99 percentile: 0.1271446031597316\n",
      "Throughput (requests per second): 10.224047073532814\n",
      "Peak response time: 0.1346001110000543\n"
     ]
    }
   ],
   "source": [
    "print('Predictions results in single thread')\n",
    "get_preds_single_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations results in single thread\n",
      "Number of requests: 100\n",
      "Total response time: 0:00:03.964165\n",
      "Mean response time: 0:00:00.039300\n",
      "99 percentile: 0:00:00.048409\n",
      "Throughput (requests per second): 25.225993368086343\n",
      "Peak response time: 0:00:00.048746\n"
     ]
    }
   ],
   "source": [
    "print('Recommendations results in single thread')\n",
    "get_recs_single_thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
