{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install aiohttp\n",
    "# %pip install mysql-connector-python\n",
    "# %pip install nest_asyncio\n",
    "# %pip install lenskit --upgrade\n",
    "# %pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import aiohttp\n",
    "import json\n",
    "import sqlite3\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer, String\n",
    "import urllib\n",
    "from pandas.io import sql\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import requests\n",
    "from time import perf_counter\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigReader:\n",
    "    def get_value(self, key):\n",
    "        with open('config.json') as json_data_file:\n",
    "            data = json.load(json_data_file)\n",
    "        return data[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DbManager:\n",
    "    def __init__(self):\n",
    "        reader = ConfigReader()\n",
    "        db_connection = reader.get_value(\"db_connection\")        \n",
    "        self.conn_string = '{db_engine}{connector}://{user}:{password}@{server}/{database}?port={port}'.format(\n",
    "            db_engine=db_connection['db_engine'],\n",
    "            connector=db_connection['connector'],\n",
    "            user=db_connection['user'],\n",
    "            password=db_connection['password'],\n",
    "            server=db_connection['server'],\n",
    "            database=db_connection['database'],\n",
    "            port=db_connection['port'])\n",
    "\n",
    "    def get_users(self):\n",
    "        # postgres:\n",
    "#        return sql.read_sql(\"SELECT distinct \\\"user\\\" FROM rating;\", create_engine(self.conn_string))\n",
    "        # mysql:\n",
    "        return sql.read_sql(\"SELECT distinct user FROM rating;\", create_engine(self.conn_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction and recommendation endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction and recommendations methods with semaphore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "throughputs = []\n",
    "\n",
    "def print_stats(times, time_taken_all, num_requests):\n",
    "    print(f'Total response time: {round(time_taken_all, 3)}')\n",
    "    print(f'Throughput (requests per second): {round(num_requests / time_taken_all, 3)}')\n",
    "    print(f'Peak response time: {round(max(times), 3)}')\n",
    "    print(f'Mean response time: {round(np.mean(times), 3)}')\n",
    "    print(f'99 percentile: {round(np.quantile(times, 0.99), 3)}')\n",
    "\n",
    "# Predictions    \n",
    "async def get_preds_sem(num_sem, algo_pred, file_name=None, add_throughput=False):\n",
    "    times = []\n",
    "    sem = asyncio.Semaphore(num_sem)\n",
    "    tasks = []    \n",
    "    num_requests = len(n_rand_users)\n",
    "    print(f'Number of requests: {num_requests}')\n",
    "    start_preds = perf_counter()\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for idx, row in n_rand_users.iterrows():\n",
    "            task = asyncio.ensure_future(get_user_preds_with_sem(row['user'], algo_pred, items, session, sem, times))\n",
    "            tasks.append(task)         \n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        time_taken_all = perf_counter() - start_preds\n",
    "        print_stats(times, time_taken_all, num_requests)\n",
    "        \n",
    "        if file_name != None and file_name != '':\n",
    "            if os.path.exists(file_name):\n",
    "                os.remove(file_name)\n",
    "            obj = {'times': times, 'time_taken_all': time_taken_all, 'num_requests': num_requests}\n",
    "            pickle.dump(obj, open(file_name, \"wb\"))\n",
    "        \n",
    "        if add_throughput:\n",
    "            throughputs.append(num_requests / time_taken_all)\n",
    "\n",
    "async def get_user_preds_with_sem(user, algo, items, session, sem, times):\n",
    "    async with sem:  # semaphore limits num of simultaneous downloads\n",
    "        return await get_user_preds_sem(user, algo, items, session, times)        \n",
    "        \n",
    "async def get_user_preds_sem(user, algo, items, session, times):\n",
    "    url = f'{base_url}/algorithms/{algo}/predictions?user_id={user}&items={items}'\n",
    "    start = perf_counter()\n",
    "    async with session.get(url) as resp:\n",
    "        data = await resp.json()    \n",
    "        time_taken = perf_counter() - start\n",
    "        times.append(time_taken)\n",
    "        \n",
    "# Recommendations\n",
    "async def get_recs_sem(num_sem, algo_rec, file_name=None, add_throughput=False):\n",
    "    times = []\n",
    "    sem = asyncio.Semaphore(num_sem)\n",
    "    tasks = []\n",
    "    num_requests = len(n_rand_users)\n",
    "    print(f'Number of requests: {num_requests}')\n",
    "    start_preds = perf_counter()\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for idx, row in n_rand_users.iterrows():\n",
    "            task = asyncio.ensure_future(get_user_recs_with_sem(row['user'], algo_rec, n_recs, session, sem, times))\n",
    "            tasks.append(task)         \n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        time_taken_all = perf_counter() - start_preds\n",
    "        print_stats(times, time_taken_all, num_requests)\n",
    "        \n",
    "        if file_name != None and file_name != '':\n",
    "            if os.path.exists(file_name):\n",
    "                os.remove(file_name)\n",
    "            obj = {'times': times, 'time_taken_all': time_taken_all, 'num_requests': num_requests}\n",
    "            pickle.dump(obj, open(file_name, \"wb\"))\n",
    "        \n",
    "        if add_throughput:\n",
    "            throughputs.append(num_requests / time_taken_all)\n",
    "\n",
    "async def get_user_recs_with_sem(user, algo, n_recs, session, sem, times):\n",
    "    async with sem:  # semaphore limits num of simultaneous downloads\n",
    "        return await get_user_preds_sem(user, algo, n_recs, session, times)        \n",
    "        \n",
    "async def get_user_recs_sem(user, algo, n_recs, session, times):\n",
    "    url = f'{base_url}/algorithms/{algo}/recommendations?user_id={user}&num_recs={n_recs}'\n",
    "    start = perf_counter()\n",
    "    async with session.get(url) as resp:\n",
    "        data = await resp.json()    \n",
    "        time_taken = perf_counter() - start\n",
    "        times.append(time_taken)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gunicorn methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def get_gunicorn_master_pid():\n",
    "    proc1 = subprocess.Popen(['ps', 'ax'], stdout=subprocess.PIPE)\n",
    "    proc2 = subprocess.Popen(['grep', 'gunicorn'], stdin=proc1.stdout,\n",
    "                             stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "\n",
    "    proc1.stdout.close() # Allow proc1 to receive a SIGPIPE if proc2 exits.\n",
    "    out, err = proc2.communicate()\n",
    "    process_length = ConfigReader().get_value('process_length')\n",
    "    master_id = out[:process_length].decode('utf-8').replace(' ', '')\n",
    "    return master_id\n",
    "\n",
    "def add_workers(n):\n",
    "    master_id = get_gunicorn_master_pid()\n",
    "    for i in range(n):\n",
    "        os.system(f\"sudo kill -s TTIN {master_id}\")\n",
    "        \n",
    "def remove_workers(n):\n",
    "    master_id = get_gunicorn_master_pid()\n",
    "    for i in range(n):\n",
    "        os.system(f\"sudo kill -s TTOU {master_id}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get config values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = ConfigReader()\n",
    "n_rand_users = num_requests = reader.get_value(\"num_requests\")\n",
    "base_url = reader.get_value(\"rec_server_base_url\")\n",
    "n_recs = reader.get_value(\"n_recs\")\n",
    "items = reader.get_value(\"items\")\n",
    "pred_algos = reader.get_value(\"pred_algos\")\n",
    "rec_algos = reader.get_value(\"rec_algos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get random users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbManager = DbManager()\n",
    "db_users = dbManager.get_users()\n",
    "n_rand_users = db_users.sample(n=n_rand_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm up phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "async def warm_up_async(current_algo=None, num_workers=24, display_logs=True):\n",
    "    warm_up_user = 1\n",
    "    times = []\n",
    "    tasks = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for algo in pred_algos:\n",
    "            if current_algo is None or algo == current_algo:\n",
    "                for w in range(num_workers * 2):\n",
    "                    if display_logs:\n",
    "                        print(f'Calling {algo}. Worker number: {w + 1}')\n",
    "                    task = asyncio.ensure_future(get_user_preds_sem(warm_up_user, algo, items, session, times))\n",
    "                    tasks.append(task)\n",
    "        responses = await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warm_up(current_algo=None, num_workers=24, display_logs=True):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    future = asyncio.ensure_future(warm_up_async(current_algo, num_workers, display_logs))\n",
    "    loop.run_until_complete(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling bias. Worker number: 1\n",
      "Calling bias. Worker number: 2\n",
      "Calling bias. Worker number: 3\n",
      "Calling bias. Worker number: 4\n",
      "Calling bias. Worker number: 5\n",
      "Calling bias. Worker number: 6\n",
      "Calling bias. Worker number: 7\n",
      "Calling bias. Worker number: 8\n",
      "Calling itemitem. Worker number: 1\n",
      "Calling itemitem. Worker number: 2\n",
      "Calling itemitem. Worker number: 3\n",
      "Calling itemitem. Worker number: 4\n",
      "Calling itemitem. Worker number: 5\n",
      "Calling itemitem. Worker number: 6\n",
      "Calling itemitem. Worker number: 7\n",
      "Calling itemitem. Worker number: 8\n",
      "Calling useruser. Worker number: 1\n",
      "Calling useruser. Worker number: 2\n",
      "Calling useruser. Worker number: 3\n",
      "Calling useruser. Worker number: 4\n",
      "Calling useruser. Worker number: 5\n",
      "Calling useruser. Worker number: 6\n",
      "Calling useruser. Worker number: 7\n",
      "Calling useruser. Worker number: 8\n",
      "Calling biasedmf. Worker number: 1\n",
      "Calling biasedmf. Worker number: 2\n",
      "Calling biasedmf. Worker number: 3\n",
      "Calling biasedmf. Worker number: 4\n",
      "Calling biasedmf. Worker number: 5\n",
      "Calling biasedmf. Worker number: 6\n",
      "Calling biasedmf. Worker number: 7\n",
      "Calling biasedmf. Worker number: 8\n",
      "Calling implicitmf. Worker number: 1\n",
      "Calling implicitmf. Worker number: 2\n",
      "Calling implicitmf. Worker number: 3\n",
      "Calling implicitmf. Worker number: 4\n",
      "Calling implicitmf. Worker number: 5\n",
      "Calling implicitmf. Worker number: 6\n",
      "Calling implicitmf. Worker number: 7\n",
      "Calling implicitmf. Worker number: 8\n",
      "Calling funksvd. Worker number: 1\n",
      "Calling funksvd. Worker number: 2\n",
      "Calling funksvd. Worker number: 3\n",
      "Calling funksvd. Worker number: 4\n",
      "Calling funksvd. Worker number: 5\n",
      "Calling funksvd. Worker number: 6\n",
      "Calling funksvd. Worker number: 7\n",
      "Calling funksvd. Worker number: 8\n"
     ]
    },
    {
     "ename": "ContentTypeError",
     "evalue": "0, message='Attempt to decode JSON with unexpected mimetype: text/html; charset=utf-8', url=URL('http://127.0.0.1:5000/algorithms/implicitmf/predictions?user_id=1&items=10,20,30,40,50')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mContentTypeError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-82e0169c3400>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-40a8ee3a54ce>\u001b[0m in \u001b[0;36mwarm_up\u001b[0;34m(current_algo, num_workers, display_logs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarm_up_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_algo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisplay_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     93\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     94\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0mevents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_running_loop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_must_cancel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-07a2a514e0a2>\u001b[0m in \u001b[0;36mwarm_up_async\u001b[0;34m(current_algo, num_workers, display_logs)\u001b[0m\n\u001b[1;32m     11\u001b[0m                     \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_future\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_user_preds_sem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarm_up_user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mtasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mresponses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__wakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;31m# This may also be a cancellation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-b4a439768521>\u001b[0m in \u001b[0;36mget_user_preds_sem\u001b[0;34m(user, algo, items, session, times)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_taken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/aiohttp/client_reqrep.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, encoding, loads, content_type)\u001b[0m\n\u001b[1;32m   1029\u001b[0m                     message=('Attempt to decode JSON with '\n\u001b[1;32m   1030\u001b[0m                              'unexpected mimetype: %s' % ctype),\n\u001b[0;32m-> 1031\u001b[0;31m                     headers=self.headers)\n\u001b[0m\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0mstripped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_body\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mContentTypeError\u001b[0m: 0, message='Attempt to decode JSON with unexpected mimetype: text/html; charset=utf-8', url=URL('http://127.0.0.1:5000/algorithms/implicitmf/predictions?user_id=1&items=10,20,30,40,50')"
     ]
    }
   ],
   "source": [
    "warm_up(None, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call predict and recommend endpoints from server for canonical config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions for different algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for algo in pred_algos:\n",
    "    file_name = f'preds_{algo}_workers_4_num_req_{num_requests}.pickle'\n",
    "    loop = asyncio.get_event_loop()\n",
    "    print(f'Algorithm: {algo}')\n",
    "    future = asyncio.ensure_future(get_preds_sem(8, algo, file_name, True))\n",
    "    loop.run_until_complete(future)\n",
    "    print('---------------------')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for algo_rec in rec_algos:\n",
    "    print(f'Algorithm: {algo_rec}')\n",
    "    file_name = f'recs_{algo_rec}_workers_4_num_req_{num_requests}.pickle'\n",
    "    loop = asyncio.get_event_loop()\n",
    "    future = asyncio.ensure_future(get_recs_sem(8, algo_rec, file_name))\n",
    "    loop.run_until_complete(future)\n",
    "    print('---------------------')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lenskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "from binpickle import BinPickleFile\n",
    "from pathlib import Path\n",
    "\n",
    "directory_path = 'models'\n",
    "\n",
    "def exists_model_file(algo):\n",
    "    full_file_name = Path(directory_path) / algo\n",
    "    if full_file_name.exists():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def load_for_shared_mem(file_name):\n",
    "    full_file_name = Path(directory_path) / file_name\n",
    "\n",
    "    binpickle_file = BinPickleFile(full_file_name, direct=True)\n",
    "    model = binpickle_file.load()\n",
    "    return model\n",
    "\n",
    "def get_predictions_from_model(model, user, items):\n",
    "    try:\n",
    "        results = []\n",
    "        df_preds = model.predict_for_user(user, items)\n",
    "        for index, value in df_preds.iteritems():\n",
    "            if not math.isnan(value):\n",
    "                results.append({'item': index, 'score': value})\n",
    "        return results\n",
    "    except:\n",
    "        print(f\"Unexpected preds error for user: {user}, with items: {items}. Error: {sys.exc_info()[0]}\")\n",
    "        raise\n",
    "        \n",
    "\n",
    "# Predictions    \n",
    "async def get_preds_threads_lkpy(num_sem, model, file_name=None, add_throughput=False):\n",
    "    times = []\n",
    "    sem = asyncio.Semaphore(num_sem)\n",
    "    tasks = []    \n",
    "    num_requests = len(n_rand_users)\n",
    "    print(f'Number of requests: {num_requests}')\n",
    "    start_preds = perf_counter()\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for idx, row in n_rand_users.iterrows():\n",
    "            task = asyncio.ensure_future(get_user_preds_with_threads_lkpy(row['user'], items, session, sem, times, model))\n",
    "            tasks.append(task)         \n",
    "\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        time_taken_all = perf_counter() - start_preds\n",
    "        print_stats(times, time_taken_all, num_requests)\n",
    "        \n",
    "        if file_name != None and file_name != '':\n",
    "            if os.path.exists(file_name):\n",
    "                os.remove(file_name)\n",
    "            obj = {'times': times, 'time_taken_all': time_taken_all, 'num_requests': num_requests}\n",
    "            pickle.dump(obj, open(file_name, \"wb\"))\n",
    "        \n",
    "        if add_throughput:\n",
    "            throughputs.append(num_requests / time_taken_all)\n",
    "\n",
    "async def get_user_preds_with_threads_lkpy(user, items, session, sem, times, model):\n",
    "    async with sem:  # semaphore limits num of simultaneous downloads\n",
    "        return await get_user_preds_threads_lkpy(user, items, session, times, model)        \n",
    "        \n",
    "async def get_user_preds_threads_lkpy(user, items, session, times, model):\n",
    "    try:\n",
    "        start = perf_counter()\n",
    "        results = []\n",
    "        df_preds = model.predict_for_user(user, list(map(int, items.split(','))))\n",
    "        for index, value in df_preds.iteritems():\n",
    "            if not math.isnan(value):\n",
    "                results.append({'item': index, 'score': value})\n",
    "                \n",
    "        time_taken = perf_counter() - start\n",
    "        times.append(time_taken)\n",
    "        return results\n",
    "    except:\n",
    "        print(f\"Unexpected preds error for user: {user}, with items: {items}. Error: {sys.exc_info()[0]}\")\n",
    "        raise        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import train_save_model\n",
    "lk_recserver_algos = reader.get_value('lk_recserver_algos')\n",
    "lk_recserver_algos_not_created = []\n",
    "for a in lk_recserver_algos:\n",
    "    if not exists_model_file(f'{a}.bpk'):\n",
    "        lk_recserver_algos_not_created.append(a)\n",
    "if len(lk_recserver_algos_not_created) > 0:\n",
    "    train_save_model.save_models(lk_recserver_algos_not_created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lenskit performance:')\n",
    "for lk_recserver_algo in lk_recserver_algos:\n",
    "    print(f'Algo: {lk_recserver_algo}')\n",
    "    model = load_for_shared_mem(f'{lk_recserver_algo}.bpk')\n",
    "    file_name = f'lkpy_{lk_recserver_algo}_num_req_{num_requests}.pickle'\n",
    "    loop = asyncio.get_event_loop()\n",
    "    future = asyncio.ensure_future(get_preds_threads_lkpy(8, model, file_name))\n",
    "    loop.run_until_complete(future)\n",
    "    print('------------------')    \n",
    "    warm_up(lk_recserver_algo, 8, False)\n",
    "    print('Recommendation server performance:')\n",
    "    file_name = f'preds_{lk_recserver_algo}_against_lkpy_workers_4_num_req_{num_requests}.pickle'\n",
    "    loop = asyncio.get_event_loop()\n",
    "    future = asyncio.ensure_future(get_preds_sem(8, lk_recserver_algo, file_name, True))\n",
    "    loop.run_until_complete(future)\n",
    "    print('*******************************************************')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speedup Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throughputs = []\n",
    "linear_speedup_algos = reader.get_value(\"linear_speedup_algos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_server(file_name, num_sem):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    future = asyncio.ensure_future(get_preds_sem(num_sem, current_algo, file_name, True))\n",
    "    loop.run_until_complete(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers_config = reader.get_value(\"workers_config\")\n",
    "inc_config = reader.get_value(\"inc_config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for current_algo in linear_speedup_algos:\n",
    "    i = 0\n",
    "    throughputs = []\n",
    "    remove_workers(3) # reduce from 4 workers to 1\n",
    "    for num_workers in workers_config:\n",
    "        print(f'Algo: {current_algo}, Workers: {num_workers}')\n",
    "        warm_up(current_algo, num_workers, display_logs=False)\n",
    "        file_name = f'linear_speedup_preds_{current_algo}_workers_{num_workers}_num_req_{num_requests}.pickle'\n",
    "        call_server(file_name, num_workers)\n",
    "        if (num_workers != workers_config[-1]):\n",
    "            print(f'add {inc_config[i]} workers')\n",
    "            add_workers(inc_config[i])\n",
    "        i += 1\n",
    "        print('------------------')\n",
    "    throughput_file_name_workers = f'throughput_single_multiple_workers_algo_{current_algo}.csv'\n",
    "    np.savetxt(throughput_file_name_workers, throughputs , delimiter=',')\n",
    "\n",
    "    remove_workers(workers_config[-1] - 4) # remove workers to get only 4 (default config)\n",
    "    print('*******************************************************')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
